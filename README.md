# Turkish Question Answering

This is our Bachelor's graduation thesis from Yildiz Technical University on question answering systems with deep learning. [Bet√ºl √ñn](https://github.com/betulON) and I collected  610 paragraphs from Turkish Wikipedia and extracted 5,000 question-answer pairs from them. With this dataset we fine-tuned [Turkish BERT](https://huggingface.co/dbmdz/bert-base-turkish-cased), [ALBERT](https://huggingface.co/loodos/albert-base-turkish-uncased), and [ELECTRA](https://huggingface.co/dbmdz/electra-base-turkish-cased-discriminator) for the question-answering task. We achieved 68% exact-match and 81% F1 score, 49% exact-match and 68% F1 score, and 66% exact-match and 82% F1 score with BERT, ALBERT, and ELECTRA respectively. We are thankful to our supervisor Prof. Dr. [Banu Diri](https://avesis.yildiz.edu.tr/diri) for her excellent mentorship. Thank you to [Bayerische Staatsbibliothek](https://huggingface.co/dbmdz) and [Loodos](https://huggingface.co/loodos) for this great pre-trained turkish models. And thank you to [Huggingface](https://github.com/huggingface) for the all transformers and tokenizers.

## Dataset Format ‚úè

## BERT, ALBERT, ELECTRA Architectures ‚öô

## Test Results üìä

## WEB GUI üíª
