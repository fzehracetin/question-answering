{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Extraction with BERT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4e2f0f8926944d9bbf15e14e30c24ffc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a91e513f935644d7af33f0a6c689c9a1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28612f832c464523b8a3991b594c5d12","IPY_MODEL_15fd2fface0c4a46ba776cce5066594f"]}},"a91e513f935644d7af33f0a6c689c9a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28612f832c464523b8a3991b594c5d12":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1d6b8f0897724504a241c5c7b11fe241","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":251003,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":251003,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c93da2d9ce184bd68557ceea9a45e3e7"}},"15fd2fface0c4a46ba776cce5066594f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57683e0410cd421b955bc9f160a39199","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 251k/251k [00:00&lt;00:00, 498kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_772af731da5042b2be936dcbf394ca94"}},"1d6b8f0897724504a241c5c7b11fe241":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c93da2d9ce184bd68557ceea9a45e3e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57683e0410cd421b955bc9f160a39199":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"772af731da5042b2be936dcbf394ca94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"677dd16227b248b7a092d2ea75ff4abc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_edd5f4051bf64e7a893b50ba37401393","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_560ed9f8e2d64a588bbdb366627cf7fe","IPY_MODEL_6e733372fb254e12a9f28285fd4c2a9e"]}},"edd5f4051bf64e7a893b50ba37401393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"560ed9f8e2d64a588bbdb366627cf7fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6a0e3b2e90a34a5597a393a22f975cb7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":60,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":60,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5009c6f880d2401bafd839afb135d20f"}},"6e733372fb254e12a9f28285fd4c2a9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db0b4276b92a4c04af6a570d237fb6e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 60.0/60.0 [00:00&lt;00:00, 256B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69d34ac12fdb45a28d074946b9e25375"}},"6a0e3b2e90a34a5597a393a22f975cb7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5009c6f880d2401bafd839afb135d20f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db0b4276b92a4c04af6a570d237fb6e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"69d34ac12fdb45a28d074946b9e25375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gjwDhSG_89hb"},"source":["# Text Extraction with BERT"]},{"cell_type":"markdown","metadata":{"id":"x18sQgfwNpsm"},"source":["Resource: [Text Extraction with Bert](https://keras.io/examples/nlp/text_extraction_with_bert/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3J74DSyH9VzL","executionInfo":{"status":"ok","timestamp":1622729839951,"user_tz":-180,"elapsed":19357,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"b8eed164-932d-477e-99bd-96df8ea902df"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ROpJgf1l9Eav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622729855106,"user_tz":-180,"elapsed":11803,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"25e2b142-1465-4a11-919e-f19237d0117a"},"source":["! pip install transformers\n","! pip install tokenizers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 24.6MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 32.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lnl0Y7z989hk","executionInfo":{"status":"ok","timestamp":1622729860039,"user_tz":-180,"elapsed":4937,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["import json\n","import os\n","import random\n","import numpy as np\n","import collections\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from transformers import BertTokenizer, TFBertModel, BertConfig\n","from tokenizers import BertWordPieceTokenizer"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHOU9WH289hm","executionInfo":{"status":"ok","timestamp":1622729860041,"user_tz":-180,"elapsed":16,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["class WikiElement:\n","    def __init__(self, question, context, answer, answer_start, answer_end):\n","        self.question = question\n","        self.context = context\n","        self.answer = answer\n","        self.answer_start = answer_start\n","        self.answer_end = answer_end\n","        \n","    def preprocess(self):\n","        # create context vector with answers marked\n","        context_vector = [0] * len(self.context)\n","        \n","        for index in range(self.answer_start, self.answer_end):\n","          context_vector[index] = 1\n","\n","        # tokenize context   \n","        tokenized_context = tokenizer.encode(self.context)\n","        \n","        # find answer token indices \n","        answer_token_index = []\n","        for index, (start, end)  in enumerate(tokenized_context.offsets):\n","            if sum(context_vector[start:end]) > 0: # if token is answer\n","                answer_token_index.append(index)\n","        \n","        if len(answer_token_index) == 0:\n","            return 0\n","        \n","        # start and end token index\n","        start_token_index = answer_token_index[0]\n","        end_token_index = answer_token_index[-1]\n","        \n","        # tokenize question\n","        tokenized_question = tokenizer.encode(self.question)\n","\n","        # create inputs       \n","        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n","        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n","            \n","        attention_mask = [1] * len(input_ids)\n","        \n","        # padding for equal lenght sequence\n","        padding_length = max_len - len(input_ids)\n","        if padding_length > 0: # pad\n","            input_ids = input_ids + ([0] * padding_length)\n","            attention_mask = attention_mask + ([0] * padding_length) # len(input) [1] + padding [0]\n","            token_type_ids = token_type_ids + ([0] * padding_length) # context [0] + question [1] + padding [0]\n","        elif padding_length < 0:\n","            return 0\n","        \n","        self.input_ids = input_ids\n","        self.token_type_ids = token_type_ids\n","        self.attention_mask = attention_mask\n","        self.start_token_index = start_token_index\n","        self.end_token_index = end_token_index\n","        self.context_token_to_char = tokenized_context.offsets\n","        return 1   \n","      \n","    def class_print(self):\n","        print(\"Question: {}\\nAnswer: {}\\nAnswer Start: {}\\nAnswer End: {}\\nContext: {}\".format(self.question, \n","                                                                                              self.answer,  \n","                                                                                              self.answer_start, \n","                                                                                              self.answer_end,\n","                                                                                              self.context))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"-MpTho0t89hn","executionInfo":{"status":"ok","timestamp":1622729891530,"user_tz":-180,"elapsed":189,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["def read_json(file_name):\n","    with open(file_name, \"r\", encoding=\"utf-8\") as json_file:\n","        data = json.load(json_file)\n","    return data\n","\n","def json_to_list(json_dataset):\n","    dataset = []\n","    for paragraph_element in json_dataset[\"data\"]:\n","        for question_element in paragraph_element[\"qas\"]:\n","            dataset.append(WikiElement(question_element[\"question\"],\n","                                       paragraph_element[\"text\"],\n","                                       question_element[\"answer\"],\n","                                       question_element[\"answer_start\"],\n","                                       question_element[\"answer_end\"]))\n","    print(\"Number of questions: \", len(dataset))\n","    return dataset\n","\n","def create_input_targets(dataset):\n","    dataset_dict = {\n","        \"input_ids\": [],\n","        \"token_type_ids\": [],\n","        \"attention_mask\": [],\n","        \"start_token_index\": [],\n","        \"end_token_index\": [],\n","    }\n","    i=0\n","    for item in dataset:\n","        # print(i)\n","        i = i + 1\n","        # print(item.class_print())\n","        for key in dataset_dict:\n","            dataset_dict[key].append(getattr(item, key))\n","            \n","    for key in dataset_dict:\n","        dataset_dict[key] = np.array(dataset_dict[key])\n","        \n","    x = [\n","        dataset_dict[\"input_ids\"],\n","        dataset_dict[\"token_type_ids\"],\n","        dataset_dict[\"attention_mask\"],\n","    ]\n","    \n","    y = [dataset_dict[\"start_token_index\"], dataset_dict[\"end_token_index\"]]\n","    return x, y\n","\n","def find_max_length(dataset):\n","    max_ = 0\n","    index = 0\n","    i = 0\n","    for element in dataset:\n","        tokenized_question = tokenizer.encode(element.question)\n","        tokenized_context = tokenizer.encode(element.context)\n","        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n","        \n","        if len(input_ids) > max_:\n","            max_ = len(input_ids)\n","            index = i\n","        i += 1\n","        \n","    print(\"Max length: {}, Index: {}\".format(max_, index))\n","    return max_\n","\n","def train_test_split(dataset):\n","    random.shuffle(dataset) \n","    cut = int(len(dataset)*0.1)\n","    train, test = dataset[:-cut], dataset[-cut:] \n","    \n","    return train, test\n","\n","def create_model():\n","    ## BERT encoder\n","    encoder = TFBertModel.from_pretrained(MODEL_NAME)\n","    \n","    # QA model\n","    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    embedding = encoder.bert(input_ids, \n","                             token_type_ids=token_type_ids, \n","                             attention_mask=attention_mask)[0]\n","    \n","    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n","    start_logits = layers.Flatten()(start_logits)\n","    \n","    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n","    end_logits = layers.Flatten()(end_logits)\n","    \n","    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n","    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n","    \n","    model = keras.Model(\n","        inputs=[input_ids, token_type_ids, attention_mask],\n","        outputs=[start_probs, end_probs],\n","    )\n","    \n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n","    optimizer = keras.optimizers.Adam(lr=5e-5)\n","    model.compile(optimizer=optimizer, loss=[loss, loss])\n","    return model"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhJivsbAC1i7","executionInfo":{"status":"ok","timestamp":1622729895037,"user_tz":-180,"elapsed":217,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["import pickle\n","\n","def save_data_as_file(data, file_name):\n","  with open(path + file_name + \".dat\", \"wb\") as f:\n","    pickle.dump(data, f)\n","\n","def read_saved_data(file_name):\n","  with open(path + file_name + \".dat\", \"rb\") as f:\n","    data = pickle.load(f)\n","    return data"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"87wT60ih89hp"},"source":["\n","## Load Tokenizer"]},{"cell_type":"code","metadata":{"id":"nl9YM7Mb9x9L","executionInfo":{"status":"ok","timestamp":1622729898535,"user_tz":-180,"elapsed":192,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["path = \"/content/gdrive/MyDrive/Q&A projesi/\"\n","models_path = path + \"models/\"\n","MODEL_NAME = \"dbmdz/bert-base-turkish-cased\""],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"7JXP38Km89hp","colab":{"base_uri":"https://localhost:8080/","height":114,"referenced_widgets":["4e2f0f8926944d9bbf15e14e30c24ffc","a91e513f935644d7af33f0a6c689c9a1","28612f832c464523b8a3991b594c5d12","15fd2fface0c4a46ba776cce5066594f","1d6b8f0897724504a241c5c7b11fe241","c93da2d9ce184bd68557ceea9a45e3e7","57683e0410cd421b955bc9f160a39199","772af731da5042b2be936dcbf394ca94","677dd16227b248b7a092d2ea75ff4abc","edd5f4051bf64e7a893b50ba37401393","560ed9f8e2d64a588bbdb366627cf7fe","6e733372fb254e12a9f28285fd4c2a9e","6a0e3b2e90a34a5597a393a22f975cb7","5009c6f880d2401bafd839afb135d20f","db0b4276b92a4c04af6a570d237fb6e9","69d34ac12fdb45a28d074946b9e25375"]},"executionInfo":{"status":"ok","timestamp":1622729902829,"user_tz":-180,"elapsed":2886,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"4e5fd59a-7c5d-4871-95d0-6710bb9b6e29"},"source":["slow_tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n","splitted_model =  MODEL_NAME.split(\"/\")\n","save_path = models_path + splitted_model[0] + \"-\" + splitted_model[1] + \"/\"\n","\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","    \n","slow_tokenizer.save_pretrained(save_path)\n","tokenizer = BertWordPieceTokenizer(save_path + \"vocab.txt\", lowercase=False)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e2f0f8926944d9bbf15e14e30c24ffc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=251003.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"677dd16227b248b7a092d2ea75ff4abc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=60.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"atU_OyxE89hq"},"source":["## Load Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8KUmNG989hr","executionInfo":{"status":"ok","timestamp":1622663238397,"user_tz":-180,"elapsed":191,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"6d588d50-c9bd-4e4a-b1cb-0d5d1c1ebd97"},"source":["file_path = path + \"json_dataset/Wiki_Dataset_Final.json\"\n","json_dataset = read_json(file_path)\n","json_dataset[\"data\"][144][\"qas\"][8]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answer': 'davranışları etkileyen zihinsel süreçlerdir',\n"," 'answer_end': 1216,\n"," 'answer_start': 1173,\n"," 'id': 8,\n"," 'question': 'Bilişsel psikologların asıl odağı nedir?'}"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vSj-Qe9589hs","executionInfo":{"status":"ok","timestamp":1622663239880,"user_tz":-180,"elapsed":211,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"d9396f68-ee8f-41e6-cb8b-9ea3b157df24"},"source":["raw_dataset = json_to_list(json_dataset)\n","raw_dataset[0].class_print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of questions:  5025\n","Question: Türkiye'nin topraklarının büyük bölümü nerededir?\n","Answer: Anadolu\n","Answer Start: 69\n","Answer End: 76\n","Context: Türkiye Cumhuriyeti ya da kısaca Türkiye, topraklarının büyük bölümü Anadolu'da, küçük bir bölümü ise Balkan Yarımadası'nın güneydoğu uzantısı olan Trakya'da yer alan ülke. Kuzeybatıda Bulgaristan, batıda Yunanistan, kuzeydoğuda Gürcistan, doğuda Ermenistan, İran ve Azerbaycan'ın ekslav toprağı Nahçıvan, güneydoğuda ise Irak ve Suriye komşusudur. Güneyini Kıbrıs adası ve Akdeniz. Batısını Ege Denizi ve kuzeyini Karadeniz çevreler. Marmara Denizi ise İstanbul Boğazı ve Çanakkale Boğazı ile birlikte Anadolu'yu Trakya'dan yani Asya'yı Avrupa'dan ayırır. Türkiye, Avrupa ve Asya'nın kavşak noktasında yer alması sayesinde önemli bir jeostratejik güce sahiptir.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dc8ETKx-89ht","executionInfo":{"status":"ok","timestamp":1622663251030,"user_tz":-180,"elapsed":4508,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"5a938c16-b541-4971-cb62-09ba1f6ad94e"},"source":["# max_len = find_max_length(raw_dataset)\n","max_len = 384\n","dataset = []\n","for data in raw_dataset:\n","    result = data.preprocess()\n","    if result != 0:\n","      dataset.append(data)\n","    \n","print(\"Dataset len: \", len(dataset))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset len:  4154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rLxDSHcnD83G"},"source":["train, test = train_test_split(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ex1nrjOLDFlq"},"source":["save_data_as_file(test, \"test_384\")\n","save_data_as_file(train, \"train_384\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DpM2dGf2PZat"},"source":["## Training\n","\n"]},{"cell_type":"code","metadata":{"id":"LD57dcMNPhDp","executionInfo":{"status":"ok","timestamp":1622732108364,"user_tz":-180,"elapsed":1971,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["max_len = 384\n","train = read_saved_data(\"train_\" + str(max_len) + \"_bert\")\n","test = read_saved_data(\"test_\" + str(max_len) + \"_bert\")"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFqXr-R389hu","executionInfo":{"status":"ok","timestamp":1622732110657,"user_tz":-180,"elapsed":720,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"5ac2d19d-c651-499c-de59-ff7e1ac86de6"},"source":["x_train, y_train = create_input_targets(train)\n","x_test, y_test = create_input_targets(test)\n","\n","print(len(x_train[0]), len(x_test[0]))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["3739 415\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uti4Gpd989hv","executionInfo":{"status":"ok","timestamp":1622732112914,"user_tz":-180,"elapsed":238,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["configuration = BertConfig()  # default parameters and configuration for BERT"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4hArJC8-_u0","executionInfo":{"status":"ok","timestamp":1622732640157,"user_tz":-180,"elapsed":48430,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"3663b6b3-aefa-42d9-8bd6-12ca6baace76"},"source":["use_tpu = True\n","if use_tpu:\n","    # Create distribution strategy\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","\n","    # Create model\n","    with strategy.scope():\n","        model = create_model()\n","else:\n","    model = create_model()\n","\n","model.summary()"],"execution_count":39,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.86.25.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.86.25.26:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.86.25.26:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.86.25.26:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n","Some layers from the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at dbmdz/bert-base-turkish-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_10 (InputLayer)           [(None, 384)]        0                                            \n","__________________________________________________________________________________________________\n","input_12 (InputLayer)           [(None, 384)]        0                                            \n","__________________________________________________________________________________________________\n","input_11 (InputLayer)           [(None, 384)]        0                                            \n","__________________________________________________________________________________________________\n","bert (TFBertMainLayer)          TFBaseModelOutputWit 110617344   input_10[0][0]                   \n","                                                                 input_12[0][0]                   \n","                                                                 input_11[0][0]                   \n","__________________________________________________________________________________________________\n","start_logit (Dense)             (None, 384, 1)       768         bert[0][0]                       \n","__________________________________________________________________________________________________\n","end_logit (Dense)               (None, 384, 1)       768         bert[0][0]                       \n","__________________________________________________________________________________________________\n","flatten_6 (Flatten)             (None, 384)          0           start_logit[0][0]                \n","__________________________________________________________________________________________________\n","flatten_7 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 384)          0           flatten_6[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 384)          0           flatten_7[0][0]                  \n","==================================================================================================\n","Total params: 110,618,880\n","Trainable params: 110,618,880\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37Sl7nE989hw","executionInfo":{"status":"ok","timestamp":1622733058076,"user_tz":-180,"elapsed":55414,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"46c11e45-d91f-4ca0-aeb3-a9ed1bb92577"},"source":["# Load Weights from Drive\n","# model.load_weights(path + \"models/bertV1_weights.h5\")\n","\n","model.fit(\n","    x_train,\n","    y_train,\n","    epochs=5,  # For demonstration, 3 epochs are recommended\n","    verbose=2,\n","    batch_size=64,\n",")"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","59/59 - 11s - loss: 0.0665 - activation_6_loss: 0.0261 - activation_7_loss: 0.0404\n","Epoch 2/5\n","59/59 - 11s - loss: 0.0528 - activation_6_loss: 0.0199 - activation_7_loss: 0.0329\n","Epoch 3/5\n","59/59 - 11s - loss: 0.0388 - activation_6_loss: 0.0130 - activation_7_loss: 0.0259\n","Epoch 4/5\n","59/59 - 11s - loss: 0.0426 - activation_6_loss: 0.0188 - activation_7_loss: 0.0238\n","Epoch 5/5\n","59/59 - 11s - loss: 0.0485 - activation_6_loss: 0.0190 - activation_7_loss: 0.0295\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9b076c9f10>"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"2kL_E5cv89hw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622733077004,"user_tz":-180,"elapsed":1241,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"bf498a3d-e61a-41b4-9a41-5f38bafb6ac9"},"source":["pred_start, pred_end = model.predict(x_test)\n","count = 0\n","results = []\n","total_f1 = 0\n","for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n","  element = test[idx]\n","  offsets = element.context_token_to_char\n","  start = np.argmax(start)\n","  end = np.argmax(end)\n","\n","  if start >= len(offsets):\n","    continue\n","\n","  pred_char_start = offsets[start][0]\n","\n","  if end < len(offsets):\n","    pred_char_end = offsets[end][1]\n","    pred_ans = element.context[pred_char_start:pred_char_end]\n","  else:\n","    pred_ans = element.context[pred_char_start:]\n","\n","  pred_tokens = pred_ans.split()\n","  true_tokens = element.answer.split()\n","  common = collections.Counter(true_tokens) & collections.Counter(pred_tokens)\n","  num_same = sum(common.values())\n","\n","  if len(true_tokens) == 0 or len(pred_tokens) == 0:\n","    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","    f1 =  int(true_tokens == pred_tokens)\n","  elif num_same == 0:\n","    f1 =  0\n","  else:\n","    precision = 1.0 * num_same / len(pred_tokens)\n","    recall = 1.0 * num_same / len(true_tokens)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","  total_f1 += f1\n","\n","  results.append({\n","      \"question\": element.question,\n","      \"true answer\": element.answer,\n","      \"predicted answer\": pred_ans,\n","      \"context\": element.context,\n","      \"f1 score\": f1,\n","  })\n","\n","  # print(f\"Question: {element.question}\")\n","  # print(f\"Prediction: {pred_ans}\\nTrue Answer: {element.answer}\")\n","  # print(f\"Context: {element.context}\")\n","  # print(\"\\n\")\n","  if pred_ans == element.answer:\n","    count += 1\n","\n","acc = count / len(y_test[0])\n","F1 = total_f1 / len(y_test[0])\n","\n","print(f\"exact match:={acc:.2f} f1:={F1:.2f}\")"],"execution_count":47,"outputs":[{"output_type":"stream","text":["exact match:=0.65 f1:=0.79\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"LZTn_LuP_CfF","executionInfo":{"status":"ok","timestamp":1618665582591,"user_tz":-180,"elapsed":463,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}},"outputId":"32811ed8-b8a4-4311-c692-161e37f90671"},"source":["results[0][\"question\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Başlıca İslam mezhepleri nelerdir?'"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"xgNdtluN-Dg5","executionInfo":{"status":"ok","timestamp":1622730500195,"user_tz":-180,"elapsed":560,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["save_model_name = splitted_model[0] + \"-\" + splitted_model[1]\n","file_name = save_path + \"test-results/\" + save_model_name  + \"_10epochs_results.txt\"\n","with open(file_name, \"w\") as f:\n","  for result in results:\n","    f.write('%s\\n' %result)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nxgo-YipwZ6f"},"source":["### Save Weights to Google Drive"]},{"cell_type":"code","metadata":{"id":"U8xpx5lV2iYh","executionInfo":{"status":"ok","timestamp":1622732085100,"user_tz":-180,"elapsed":3652,"user":{"displayName":"Fatma Zehra Çetin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzWxwkSm6SQwLvKuI7eKiYtfg5Yy0_bJzt0tQigQ=s64","userId":"14276538161093709229"}}},"source":["model.save_weights(save_path + \"weights/\" + save_model_name + \"_seqlen512_epochs12\"\".h5\")"],"execution_count":28,"outputs":[]}]}