{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Text Extraction Albert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf2c925699014cf2a46f30d6ee537b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec4e7732c908430f8800e0af72cd767d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b77d0dade0d49a3b643c42524738775",
              "IPY_MODEL_52bd7b4cdd934113bf4a49a820a2d847"
            ]
          }
        },
        "ec4e7732c908430f8800e0af72cd767d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b77d0dade0d49a3b643c42524738775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d08023a252504391bf65cf3e553ec2ae",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 862541,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 862541,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7c061fae49e42f9b4c225f5621ae258"
          }
        },
        "52bd7b4cdd934113bf4a49a820a2d847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f1bdbc99f6340718be3168e383b5ffe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 863k/863k [00:01&lt;00:00, 825kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b711230e84e542d3ad30410cad2a0330"
          }
        },
        "d08023a252504391bf65cf3e553ec2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7c061fae49e42f9b4c225f5621ae258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f1bdbc99f6340718be3168e383b5ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b711230e84e542d3ad30410cad2a0330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a16defd52b046ec8e88ff18dbec0255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ebfa1af44c09476ca4fb9067c69c5114",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_541d9209fab241b4b446086bd33fab37",
              "IPY_MODEL_8447a8f39e574ad6aefa55fbfa5f2188"
            ]
          }
        },
        "ebfa1af44c09476ca4fb9067c69c5114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "541d9209fab241b4b446086bd33fab37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_62138d3afbe8405ba2044e4fcbbd66be",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 156,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 156,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf585e464e6a437cb6312bf10ba0a016"
          }
        },
        "8447a8f39e574ad6aefa55fbfa5f2188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1393dc7e852e4e8789acb69dd442daf2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 156/156 [00:00&lt;00:00, 514B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6ccdc4dca404e5b83e4140ce9260dc2"
          }
        },
        "62138d3afbe8405ba2044e4fcbbd66be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf585e464e6a437cb6312bf10ba0a016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1393dc7e852e4e8789acb69dd442daf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6ccdc4dca404e5b83e4140ce9260dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf2689343c9b4250a764b1c97ce0539b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce3108cfc4d84b559dfeee4681805345",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_516bacfd81334eb9b833a85e09f8b74c",
              "IPY_MODEL_352b80a9ab924f04a203fe97ce73e91d"
            ]
          }
        },
        "ce3108cfc4d84b559dfeee4681805345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "516bacfd81334eb9b833a85e09f8b74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89e3241986524b0c9fce61c3f91e3023",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 71,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 71,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9641ce26dc834598b2e1112acd24006f"
          }
        },
        "352b80a9ab924f04a203fe97ce73e91d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f134b6ffee624b8e89ba37a6f01d2e8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 71.0/71.0 [00:00&lt;00:00, 467B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d167f091a1e41faa838455d5aee62c4"
          }
        },
        "89e3241986524b0c9fce61c3f91e3023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9641ce26dc834598b2e1112acd24006f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f134b6ffee624b8e89ba37a6f01d2e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d167f091a1e41faa838455d5aee62c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjwDhSG_89hb"
      },
      "source": [
        "# Text Extraction with Albert\n",
        "\n",
        "> Albert\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x18sQgfwNpsm"
      },
      "source": [
        "Resource: [Text Extraction with Bert](https://keras.io/examples/nlp/text_extraction_with_bert/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J74DSyH9VzL",
        "outputId": "7c1a5175-3ab3-4e4c-cdba-f5514b8cdb9b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROpJgf1l9Eav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b69487a-0fec-4edf-b8a5-ea9e7886dfda"
      },
      "source": [
        "!pip install transformers[sentencepiece]\n",
        "!pip install tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers[sentencepiece]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.7MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 27.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (4.41.1)\n",
            "Requirement already satisfied: protobuf; extra == \"sentencepiece\" in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.12.4)\n",
            "Collecting sentencepiece==0.1.91; extra == \"sentencepiece\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 21.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[sentencepiece]) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[sentencepiece]) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[sentencepiece]) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf; extra == \"sentencepiece\"->transformers[sentencepiece]) (56.0.0)\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.10.2 transformers-4.5.1\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnl0Y7z989hk"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import transformers\n",
        "from transformers import TFAlbertModel, AlbertTokenizerFast, AlbertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWdm566-CNPr"
      },
      "source": [
        "def tokens_to_offsets(original_text, tokenized_text):\n",
        "  offsets = []\n",
        "  special_tokens_mask = tokenized_text['special_tokens_mask']\n",
        "  tokens = tokenizer.convert_ids_to_tokens(tokenized_text[\"input_ids\"])\n",
        "  index = 0\n",
        "  for i in range(len(tokens)):\n",
        "    if special_tokens_mask[i] == 1:\n",
        "      offsets.append((0, 0))\n",
        "    else:\n",
        "      new_index = index + len(tokens[i])\n",
        "      offsets.append((index, new_index))\n",
        "\n",
        "      while (new_index < len(original_text) and original_text[new_index] == ' '):\n",
        "        new_index += 1\n",
        "      index = new_index\n",
        "  return offsets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHOU9WH289hm"
      },
      "source": [
        "class WikiElement:\n",
        "    def __init__(self, question, context, answer, answer_start, answer_end):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.answer = answer\n",
        "        self.answer_start = answer_start\n",
        "        self.answer_end = answer_end\n",
        "        \n",
        "    def preprocess(self):\n",
        "        # create context vector with answers marked\n",
        "        context_vector = [0] * len(self.context)\n",
        "        for index in range(self.answer_start, self.answer_end):\n",
        "            context_vector[index] = 1\n",
        "            \n",
        "        # tokenize context   \n",
        "        tokenized_context = tokenizer(self.context, return_offsets_mapping=True)\n",
        "        context_offsets = tokenized_context['offset_mapping']\n",
        "\n",
        "        # find answer token indices \n",
        "        answer_token_index = []\n",
        "        for index, (start, end)  in enumerate(context_offsets):\n",
        "            if sum(context_vector[start:end]) > 0: # if token is answer\n",
        "                answer_token_index.append(index)\n",
        "        \n",
        "        if len(answer_token_index) == 0:\n",
        "            return 0\n",
        "        \n",
        "        # start and end token index\n",
        "        start_token_index = answer_token_index[0]\n",
        "        end_token_index = answer_token_index[-1]\n",
        "        \n",
        "        # tokenize question\n",
        "        tokenized_question = tokenizer(self.question, return_special_tokens_mask=True)\n",
        "\n",
        "        # create inputs       \n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        token_type_ids = [0] * len(tokenized_context['input_ids']) + [1] * len(tokenized_question['input_ids'][1:])\n",
        "            \n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        \n",
        "        # padding for equal lenght sequence\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0: # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length) # len(input) [1] + padding [0]\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length) # context [0] + question [1] + padding [0]\n",
        "        elif padding_length < 0:\n",
        "            return 0\n",
        "        \n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_index = start_token_index\n",
        "        self.end_token_index = end_token_index\n",
        "        self.context_token_to_char = context_offsets\n",
        "        return 1\n",
        "            \n",
        "      \n",
        "    def class_print(self):\n",
        "        print(\"Question: {}\\nAnswer: {}\\nAnswer Start: {}\\nAnswer End: {}\\nContext: {}\".format(self.question, \n",
        "                                                                                              self.answer,  \n",
        "                                                                                              self.answer_start, \n",
        "                                                                                              self.answer_end,\n",
        "                                                                                              self.context))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MpTho0t89hn"
      },
      "source": [
        "def read_json(file_name):\n",
        "    with open(file_name, \"r\", encoding=\"utf-8\") as json_file:\n",
        "        data = json.load(json_file)\n",
        "    return data\n",
        "\n",
        "def json_to_list(json_dataset):\n",
        "    dataset = []\n",
        "    for paragraph_element in json_dataset[\"data\"]:\n",
        "        for question_element in paragraph_element[\"qas\"]:\n",
        "            dataset.append(WikiElement(question_element[\"question\"],\n",
        "                                       paragraph_element[\"text\"],\n",
        "                                       question_element[\"answer\"],\n",
        "                                       question_element[\"answer_start\"],\n",
        "                                       question_element[\"answer_end\"]))\n",
        "    print(\"Number of questions: \", len(dataset))\n",
        "    return dataset\n",
        "\n",
        "def create_input_targets(dataset):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_index\": [],\n",
        "        \"end_token_index\": [],\n",
        "    }\n",
        "    i=0\n",
        "    for item in dataset:\n",
        "        # print(i)\n",
        "        i = i + 1\n",
        "        # print(item.class_print())\n",
        "        for key in dataset_dict:\n",
        "            dataset_dict[key].append(getattr(item, key))\n",
        "            \n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "        \n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    \n",
        "    y = [dataset_dict[\"start_token_index\"], dataset_dict[\"end_token_index\"]]\n",
        "    return x, y\n",
        "\n",
        "def find_max_length(dataset):\n",
        "    max_ = 0\n",
        "    index = 0\n",
        "    i = 0\n",
        "    for element in dataset:\n",
        "        tokenized_question = tokenizer(element.question)\n",
        "        tokenized_context = tokenizer(element.context)\n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        \n",
        "        if len(input_ids) > max_:\n",
        "            max_ = len(input_ids)\n",
        "            index = i\n",
        "        i += 1\n",
        "        \n",
        "    print(\"Max length: {}, Index: {}\".format(max_, index))\n",
        "    return max_\n",
        "\n",
        "def train_test_split(dataset):\n",
        "    random.shuffle(dataset) \n",
        "    cut = int(len(dataset)*0.1)\n",
        "    train, test = dataset[:-cut], dataset[-cut:] \n",
        "    \n",
        "    return train, test\n",
        "\n",
        "def create_model():\n",
        "    encoder = TFAlbertModel.from_pretrained(MODEL_NAME)\n",
        "    \n",
        "    # QA model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    embedding = encoder(input_ids,\n",
        "                        token_type_ids=token_type_ids, \n",
        "                        attention_mask=attention_mask)[0]\n",
        "    \n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "    \n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "    \n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "    \n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    \n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87wT60ih89hp"
      },
      "source": [
        "\n",
        "## Load Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl9YM7Mb9x9L"
      },
      "source": [
        "path = \"/content/gdrive/MyDrive/Q&A projesi/\"\n",
        "models_path = path + \"models/\"\n",
        "MODEL_NAME = \"loodos/albert-base-turkish-uncased\"\n",
        "model_save_name = MODEL_NAME.split(\"/\")[0] + \"-\" + MODEL_NAME.split(\"/\")[1] + \"/\"\n",
        "save_path = models_path + model_save_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "cf2c925699014cf2a46f30d6ee537b6d",
            "ec4e7732c908430f8800e0af72cd767d",
            "2b77d0dade0d49a3b643c42524738775",
            "52bd7b4cdd934113bf4a49a820a2d847",
            "d08023a252504391bf65cf3e553ec2ae",
            "e7c061fae49e42f9b4c225f5621ae258",
            "0f1bdbc99f6340718be3168e383b5ffe",
            "b711230e84e542d3ad30410cad2a0330",
            "9a16defd52b046ec8e88ff18dbec0255",
            "ebfa1af44c09476ca4fb9067c69c5114",
            "541d9209fab241b4b446086bd33fab37",
            "8447a8f39e574ad6aefa55fbfa5f2188",
            "62138d3afbe8405ba2044e4fcbbd66be",
            "cf585e464e6a437cb6312bf10ba0a016",
            "1393dc7e852e4e8789acb69dd442daf2",
            "c6ccdc4dca404e5b83e4140ce9260dc2",
            "cf2689343c9b4250a764b1c97ce0539b",
            "ce3108cfc4d84b559dfeee4681805345",
            "516bacfd81334eb9b833a85e09f8b74c",
            "352b80a9ab924f04a203fe97ce73e91d",
            "89e3241986524b0c9fce61c3f91e3023",
            "9641ce26dc834598b2e1112acd24006f",
            "f134b6ffee624b8e89ba37a6f01d2e8b",
            "9d167f091a1e41faa838455d5aee62c4"
          ]
        },
        "id": "4Z4oHmXRg98E",
        "outputId": "abb11cd4-630a-45bb-f648-3ffb9f10b3e1"
      },
      "source": [
        "tokenizer = AlbertTokenizerFast.from_pretrained(MODEL_NAME, do_lower_case=False, keep_accents=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf2c925699014cf2a46f30d6ee537b6d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=862541.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a16defd52b046ec8e88ff18dbec0255",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=156.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf2689343c9b4250a764b1c97ce0539b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=71.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wV0lAFohOf4",
        "outputId": "c7c74776-dde2-46f9-cb7d-dfb4a1820505"
      },
      "source": [
        "tokenizer(\"Hey naber\", return_offsets_mapping=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2, 1419, 98, 390, 3], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 3), (3, 5), (5, 9), (0, 0)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JXP38Km89hp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8f4eaa-c351-4899-911f-0475868dc501"
      },
      "source": [
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "    \n",
        "tokenizer.save_pretrained(save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/Q&A projesi/models/loodos-albert-base-turkish-uncased/tokenizer_config.json',\n",
              " '/content/gdrive/MyDrive/Q&A projesi/models/loodos-albert-base-turkish-uncased/special_tokens_map.json',\n",
              " '/content/gdrive/MyDrive/Q&A projesi/models/loodos-albert-base-turkish-uncased/spiece.model',\n",
              " '/content/gdrive/MyDrive/Q&A projesi/models/loodos-albert-base-turkish-uncased/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atU_OyxE89hq"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8KUmNG989hr",
        "outputId": "354f7474-ebe5-4bc4-aa7f-dfddd568ec78"
      },
      "source": [
        "file_path = path + \"json_dataset/wiki_dataV1_combined.json\"\n",
        "json_dataset = read_json(file_path)\n",
        "json_dataset[\"data\"][0][\"qas\"][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Bulgaristan',\n",
              " 'answer_end': 196,\n",
              " 'answer_start': 185,\n",
              " 'id': 1,\n",
              " 'question': \"Türkiye'nin kuzeybatısındaki komşusu kimdir?\"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSj-Qe9589hs",
        "outputId": "955abb14-b4e6-40e6-cf71-66ca8603e14d"
      },
      "source": [
        "raw_dataset = json_to_list(json_dataset)\n",
        "raw_dataset[0].class_print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of questions:  2234\n",
            "Question: Türkiye'nin topraklarının büyük bölümü nerededir?\n",
            "Answer: Anadolu\n",
            "Answer Start: 69\n",
            "Answer End: 76\n",
            "Context: Türkiye Cumhuriyeti ya da kısaca Türkiye, topraklarının büyük bölümü Anadolu'da, küçük bir bölümü ise Balkan Yarımadası'nın güneydoğu uzantısı olan Trakya'da yer alan ülke. Kuzeybatıda Bulgaristan, batıda Yunanistan, kuzeydoğuda Gürcistan, doğuda Ermenistan, İran ve Azerbaycan'ın ekslav toprağı Nahçıvan, güneydoğuda ise Irak ve Suriye komşusudur. Güneyini Kıbrıs adası ve Akdeniz. Batısını Ege Denizi ve kuzeyini Karadeniz çevreler. Marmara Denizi ise İstanbul Boğazı ve Çanakkale Boğazı ile birlikte Anadolu'yu Trakya'dan yani Asya'yı Avrupa'dan ayırır. Türkiye, Avrupa ve Asya'nın kavşak noktasında yer alması sayesinde önemli bir jeostratejik güce sahiptir.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc8ETKx-89ht",
        "outputId": "e5d01426-7730-4e80-b3ef-b6e15a471998"
      },
      "source": [
        "max_len = 512\n",
        "\n",
        "dataset = []\n",
        "for data in raw_dataset:\n",
        "    flag = data.preprocess()\n",
        "    if flag == 1:\n",
        "      dataset.append(data)\n",
        "    \n",
        "print(\"Dataset len: \", len(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset len:  2013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFqXr-R389hu",
        "outputId": "5c1c4884-82f5-4019-b850-0184789135bc"
      },
      "source": [
        "train, test = train_test_split(dataset)\n",
        "\n",
        "x_train, y_train = create_input_targets(train)\n",
        "x_test, y_test = create_input_targets(test)\n",
        "\n",
        "print(len(x_train[0]), len(y_train[0]), len(x_test[0]), len(y_test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1812 1812 201 201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uti4Gpd989hv"
      },
      "source": [
        "configuration = transformers.AlbertConfig()  # default parameters and configuration for BERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4hArJC8-_u0",
        "outputId": "1bf9fe99-6f11-4bf5-ba3c-2cb5e9fd85a3"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model = create_model()\n",
        "else:\n",
        "    model = create_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.20.97.186:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.20.97.186:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.20.97.186:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.20.97.186:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "All model checkpoint layers were used when initializing TFAlbertModel.\n",
            "\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at loodos/albert-base-turkish-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model_1 (TFAlbertMode TFBaseModelOutputWit 11939584    input_4[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 512, 1)       768         tf_albert_model_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 512, 1)       768         tf_albert_model_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 512)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 512)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 512)          0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 512)          0           flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 11,941,120\n",
            "Trainable params: 11,941,120\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Sl7nE989hw",
        "outputId": "77d33334-e68f-43f3-ad76-b301aec84406"
      },
      "source": [
        "# Load Weights from Drive\n",
        "# model.load_weights(path + \"models/bertV1_weights.h5\")\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=5,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=2,\n",
        "    batch_size=64,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "29/29 - 6s - loss: 0.3565 - activation_2_loss: 0.1983 - activation_3_loss: 0.1581\n",
            "Epoch 2/5\n",
            "29/29 - 6s - loss: 0.3147 - activation_2_loss: 0.1541 - activation_3_loss: 0.1607\n",
            "Epoch 3/5\n",
            "29/29 - 6s - loss: 0.3883 - activation_2_loss: 0.1870 - activation_3_loss: 0.2013\n",
            "Epoch 4/5\n",
            "29/29 - 6s - loss: 0.4528 - activation_2_loss: 0.2082 - activation_3_loss: 0.2447\n",
            "Epoch 5/5\n",
            "29/29 - 6s - loss: 0.4301 - activation_2_loss: 0.2006 - activation_3_loss: 0.2295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6ef4072cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kL_E5cv89hw",
        "outputId": "6bb38a82-8d9a-4fcf-a817-4045f8eb8fa4"
      },
      "source": [
        "pred_start, pred_end = model.predict(x_test)\n",
        "count = 0\n",
        "before_count = 0\n",
        "results = []\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "  element = test[idx]\n",
        "  offsets = element.context_token_to_char\n",
        "  start = np.argmax(start)\n",
        "  end = np.argmax(end)\n",
        "\n",
        "  if start >= len(offsets):\n",
        "    continue\n",
        "\n",
        "  pred_char_start = offsets[start][0]\n",
        "\n",
        "  if end < len(offsets):\n",
        "    pred_char_end = offsets[end][1]\n",
        "    pred_ans = element.context[pred_char_start:pred_char_end]\n",
        "  else:\n",
        "    pred_ans = element.context[pred_char_start:]\n",
        "  results.append({\n",
        "      \"question\": element.question,\n",
        "      \"true answer\": element.answer,\n",
        "      \"predicted answer\": pred_ans,\n",
        "      \"context\": element.context\n",
        "  })\n",
        "  # print(f\"Question: {element.question}\")\n",
        "  # print(f\"Prediction: {pred_ans}\\nTrue Answer: {element.answer}\")\n",
        "  # print(f\"Context: {element.context}\")\n",
        "  # print(\"\\n\")\n",
        "  print(\"'\" + pred_ans + \"'\" + \"  ->'\" + element.answer + \"'\")\n",
        "  if pred_ans == element.answer:\n",
        "    before_count += 1\n",
        "  if len(pred_ans) > 0 and pred_ans[0] == ' ':\n",
        "    pred_ans = pred_ans[1:]\n",
        "  if pred_ans == element.answer:\n",
        "    count += 1\n",
        "\n",
        "acc = count / len(y_test[0])\n",
        "acc2 = before_count / len(y_test[0])\n",
        "print(f\"accuracy:={acc:.2f}\")\n",
        "print(f\"before accuracy:={acc2:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "' Sklera'  ->'ağ tabaka'\n",
            "' suyu Turpgiller'  ->'Turpgiller'\n",
            "' fahri doktor'  ->'fahri doktor'\n",
            "' 28 Şubat 2017'  ->'13 Nisan 1922'\n",
            "' aylık abonelik sistemiyle'  ->'aylık abonelik sistemiyle'\n",
            "' evreni inceleyen daldır. Bu sebeple evreni genel olarak inceler; evreni doğuşundan sonuna kadar inceler, evrenin doğası ve içerdiklerinin doğasına kadar, evrene dair her şeyle ilişkilidir. Bundan farklı olarak, kozmogoni sadece evrenin doğuşu, kökeni ile ilgilidir'  ->'kozmogeni'\n",
            "''  ->'altın bilet'\n",
            "' dört'  ->'Finlandiya'\n",
            "' Charles Gounod'  ->'Charles Gounod'\n",
            "' II'  ->'çelik kasalı bir tanksavar mayını'\n",
            "''  ->'Stratum germinativum'\n",
            "' Suyun kaldırma kuvveti'  ->'Suyun kaldırma kuvveti'\n",
            "' Eski Mısır'  ->'Eski Mısır'\n",
            "''  ->'Joseph Black'\n",
            "' firari askerler ve sivil gönüllülerden'  ->'Çoğunlukla firari askerler ve sivil gönüllüler'\n",
            "' Yunanistan'  ->'Gürcistan'\n",
            "' dört ayın adlarını değiştiren yasa ile ayın adı kasım yapıldı. 1946 yılında, Refet Ülgen eylül ayı için ilk güz, kasım ayı içinse songüz adını önermiş; ancak bu önerisi benimsenmemiştir. Ayın adı bir iddiaya göre Arapça kâsim, (bölen)'den gelmektedir, ama neyi bölmektedir? Oysa Anadolu'da, bu yasa çıkmadan yüzyıllar öncesinden beri halk yılı, kasım, kasım günleri ve hızır, hızır günleri  diye ikiye'  ->'ikiye'\n",
            "''  ->'1500 yıl önce İngiltere’de kayıp oğullarını aramak üzere zorlu bir yolculuğa çıkan Axl ve Beatrice adlı yaşlı bir çift'\n",
            "' canavara çevirmiş,  Semele'  ->'canavara'\n",
            "' insani fosil yakıtlar tüketimi, endüstriyel ve tarımsal gibi faaliyetlerinin sonucu olarak atmosferdeki miktarı ve yoğunluğu artan sera gazlarının neden olduğu küresel ısınmanın neden olduğu iklim değişiklikleridir. Bu iklim değişiklikleri kuraklık, çölleşme, yağışlardaki dengesizlik ve sapmalar, su baskınları, tayfun, fırtına, hortum vb.'  ->'kuraklık, çölleşme, yağışlardaki dengesizlik ve sapmalar, su baskınları, tayfun, fırtına, hortum vb.'\n",
            "' doğrusal olmayan öykü akışını, diyalogları ve kanlı şiddet sahnelerini cesurca kullanmasıyla'  ->'doğrusal olmayan öykü akışını, diyalogları ve kanlı şiddet sahnelerini cesurca kullanmasıyla'\n",
            "'%80'  ->'80'\n",
            "' Aix-en-Provence şehrinden geçen A8 Otoyolu'  ->'A8 Otoyolu'\n",
            "'İngiltere, İskoçya, Galler ve Kuzey İrlanda.  Başkentleri sırasıyla Londra, Edinburgh, Cardiff ve Belfast'  ->'İngiltere, İskoçya, Galler ve Kuzey İrlanda'\n",
            "' Çin Halk Cumhuriyeti'  ->'Çin Halk Cumhuriyeti Hong Kong Özel İdari Bölgesi'\n",
            "' bölge sakinleri için savaş sığınağı'  ->'savaş sığınağı'\n",
            "' Madrid'  ->'Sevilla'\n",
            "' Orta Avrupa'  ->'Orta Avrupa'\n",
            "' Avusturya Parlamentosu'na'  ->'Avusturya Parlamentosu'na'\n",
            "' 1 Nisan 1976'  ->'1 Nisan 1976 '\n",
            "' uzunluk kısalık ilişkisiyle'  ->'uzunluk kısalık ilişkisiyle'\n",
            "' Nizip'in Fevkani mahallesinde'  ->'Nizip'in Fevkani mahallesinde'\n",
            "''  ->'IIHF başkanı'\n",
            "' 16 Temmuz 2008'de Avustralya'da, 18 Temmuz 2008'de Kuzey Amerika'da ve 24 Temmuz 2008'  ->'24 Temmuz 2008'\n",
            "' Stamford Raffles'ın'  ->'Stamford Raffles'\n",
            "'İngilizce, Çince, ve Hintçe dilinden'  ->'İngilizce, Çince, ve Hintçe'\n",
            "''  ->'plato'\n",
            "''  ->'Norslar'\n",
            "' davranışı ve zihini'  ->'davranışı ve zihini'\n",
            "' 42'  ->'2400'\n",
            "' Noel Baba'  ->'Noel Baba'\n",
            "''  ->'Kuyruk'\n",
            "' Beringia'  ->'Asya'dan'\n",
            "'As'  ->'gözün yeri'\n",
            "' Bilgesu Erenus'  ->'seyirlik bir oyun'\n",
            "' bir anayasal monarşi'  ->'anayasal monarşi'\n",
            "' 5 Eylül 1967'  ->'5 Eylül 1967'\n",
            "' 1836'  ->'1836'\n",
            "' indie rock'  ->'elektronik müzik ve indie rock'\n",
            "'Feminizme\" kelimesinden gelir.) \"Aynı seviyede olma durumu, eşitlik, yani emansipasyon\"dan anlaşılan (kadın ve erkek gibi) toplumsal gruplar arasındaki yaşam koşullarındaki eşitsizliğin asimile edilmesidir. “Eşit muamele” kavramından anlaşılan ise engelliler, hamileler gibi yaşam koşullarından muzdarip olan toplumsal grupların tüm yaşam alanlarında eşitlenmesi durumudur'  ->'(kadın ve erkek gibi) toplumsal gruplar arasındaki yaşam koşullarındaki eşitsizliğin asimile edilmesidir'\n",
            "' Atatürk Barış Ödülü'  ->'Atatürk Barış Ödülü'\n",
            "' SIMBAD ve NASA/IPAC gök adalar arası veri tabanında kullanmak için'  ->'literatür referans kaynaklarını belirtmek için'\n",
            "''  ->'1.104 km2'lik'\n",
            "' viola da gamba'  ->'çello'\n",
            "' devlete ihtiram, güçlü bir lidere bağlılık ve aşırı milliyetçilik ile militarizme verilen önem'  ->'devlete ihtiram, güçlü bir lidere bağlılık ve aşırı milliyetçilik ile militarizme verilen önem'\n",
            "''  ->'hayvan kullanımı yoluyla elde edilen gıdaları, giyecekleri ve diğer tüm yan ürünleri '\n",
            "' sayı boncuğu (abaküs) ve Antikitera Makinesi (M.Ö 150- M.Ö100)'  ->'sayı boncuğu (abaküs) ve Antikitera Makinesi (M.Ö 150- M.Ö100)'\n",
            "' Etrüsk alfabesi ile Yunan alfabesine'  ->'Etrüsk alfabesi ile Yunan alfabesine'\n",
            "' 50 milyon'  ->'50 milyon'\n",
            "' Bulgarca'  ->'Bulgarca'\n",
            "' 1917 Ekim Devrimi 'nden sonra'  ->'1917 Ekim Devrimi 'nden sonra'\n",
            "' 6 Mayıs günü ile başlar ve kasım'a dek'  ->'6 Mayıs'\n",
            "' 1967 yılında Ohio College Library Center (Ohio Üniversitesi Kütüphane Merkezi) adıyla kurulan OCLC ve üye kütüphaneleri dünyadaki en büyük çevrimiçi kamu erişim kataloğu olan WorldCat'i üretmekte ve geliştirmektedir. 6 Temmuz 1967'de kâr amacı gütmeyen bir kuruluş olarak Ohio Üniversitesi Kütüphane Merkezi adıyla kuruldu. 170 ülke ve bölgede 72,000'den fazla kütüphane, kütüphane gereçlerini belirlemek, ödünç almak, kataloglamak gibi işler için OCLC hizmetlerini kullanmaktadır. Kuruluş Fred Kilgour tarafından kurulmuş ve merkezi Ohio eyaletindeki Dublin şehrindedir. OCLC, herkese bibliyografik özet ve tüm metin bilgileri sunmaktadır. OCLC ve üye kütüphaneler, WorldCat kataloğunu geliştirmekte ve kullanmaktadır. WorldCat, devlet ve özel kütüphanelerden gelen kayıtları saklamaktadır. Open WorldCat programı kütüphane sahipliğindeki materyallerin OCLC WorldCat veritabanında saklanması sağlamakta ve İnternet aramaları, bibliyografik ve kitap satış sitelerinde bu bilgilerin İnternet kullanıcıları tarafından görüntülenebilmesine imkân vermektedir. Ekim 2005'  ->'6 Temmuz 1967'\n",
            "' Amerikalı bir heavy metal grubudur. Davulcu Lars Ulrich ve vokalist/gitarist James Hetfield tarafından Los Angeles'ta kurulduktan sonra kariyerinin büyük kısmını San Francisco'da sürdürmüştür. Hızlı tempoları ve agresif müziğiyle bilinen grup; Slayer, Megadeth ve Anthrax ile birlikte thrash metalin dört büyüklerinden biri olarak kabul edilir. 1981 yılında James Hetfield'ın, Lars Ulrich'in grup kurmak için yerel bir gazetede verdiği ilana yanıt vermesi ile kurulan grubun 2003 yılı itibarıyla kadrosu; vokal ve ritim gitarda James Hetfield, davulda Lars Ulrich, lead gitarda Kirk Hammett ve bas gitarda Robert Trujillo şeklindedir. Metallica'nın ilk albümü Kill 'Em All 1983 yılında yayınlandı. Grup, 1986 yılında yayınlanan ve tüm zamanların en ilham verici thrash metal albümlerinden biri olarak görülen Master of Puppets albümü ile hayran kitlesini genişletmeye başladı. Metallica, 1991 yılında yayınlanan Black Album'  ->'heavy metal'\n",
            "''  ->'İskandinavyalılardan'\n",
            "' 19'  ->'19'\n",
            "' ENIAC'  ->'ENIAC'\n",
            "' çukurunda'  ->'göz çukurunda'\n",
            "' 2004'  ->'2004'\n",
            "' tuz'  ->'şalgam'\n",
            "'kan'  ->'hak'\n",
            "'İsis'  ->'erkek'\n",
            "''  ->'bildirme, haber alma yoluyla bilgi edinme'\n",
            "' üç'  ->'üç adet'\n",
            "' Türk siyasetçi'  ->'Türk siyasetçi, eski başbakan ve eski Anavatan Partisi Genel Başkanı'\n",
            "' yıldız'  ->'logos'\n",
            "' 10,3 milyon'  ->'10,3 milyon'\n",
            "' mutant'  ->'mutant'\n",
            "''  ->'Deniz Celiloğlu ve Aras Bulut İynemli'\n",
            "' Jana Gana Mana'  ->'Jana Gana Mana'\n",
            "' üç tabakanın birleşmesinden oluşmuştur. En dıştaki birinci tabakaya, Sklera ya da \"gözakı\" denir. Bu tabaka önde tümsekleşerek, saydam Kornea tabakası olarak devam eder. Beyaz ve lifli yapıda olan bu sert tabaka, gözü dış darbelere karşı koruyan kalın bir zardır. Çok damarlı bir bağ dokusu olan damar tabaka, iki yüzündeki boyalı hücre örtüsüyle, gözyuvarını tam bir karanlık oda haline getirir. Bunun ön bölümünde, kirpiksi cisim kasları ile kirpiksi bölge yer alır; kirpiksi bölgenin çok damarlı olan asıcı bağı gergin tutmak için kanla dolan küçük piramitler halindeki çıkıntılara, \"kirpiksi uzantı\" denir. Kirpiksi bölgenin uzantısı olarak, ön bölümde damar tabaka renk değiştirerek ortası delik (gözbebeği) bir diyafram oluşturur (iris). Gözün üçüncü ve çok ince tabakası olan ağ tabaka, duyarlı bir tabakadır. Bunun arka bölümünde bulunan ortası çukur, beyazımsı küçük kabarcık (görme sinir diski), görme sinirinin girdiği yerdir ve \"kör nokta\" diye adlandırılır. Kör noktanın biraz ötesinde, sarı nokta'  ->'damar tabaka'\n",
            "' Akademi, Altın Küre, BAFTA ve Grammy ödülleri'  ->'Akademi, Altın Küre, BAFTA ve Grammy ödülleri kazanmıştır'\n",
            "' kaos'  ->'kaos teorisi, ağların önemi, karmaşa ve düzenin karşılıklı ilişkisi'\n",
            "''  ->'Elaine'\n",
            "'İsveç'  ->'Doğuda Rusya, kuzeyde Norveç ve batıda İsveç'le'\n",
            "' atmosfere salınan sera gazların'  ->'karbondioksit gibi ısıyı tutan gazların atmosferde artmasıyla'\n",
            "' Cenova ile Ventimiglia'  ->'Cenova ile Ventimiglia'\n",
            "''  ->'Dmitri Ivanovsky'\n",
            "''  ->'koni ve “S” biçiminde pirinçten'\n",
            "' beş'  ->'beş'\n",
            "' Nürnberg Yasaları'  ->'Nürnberg Yasaları'\n",
            "'İç salgı görevini Langerhans adacıkları denen salgı hücreleri'  ->'İç salgı'\n",
            "' Osiris'  ->'Piramit metinleri'\n",
            "'balet'  ->'balerin'\n",
            "''  ->'vokalist'\n",
            "' Semele'  ->'ayı'\n",
            "' Lieselotte'  ->'Hildegard ve Wilhelm Ritschel'\n",
            "' On bin kadar'  ->'On bin'\n",
            "' Cezayir'  ->'Nijerya'\n",
            "' germ hattı'  ->'germ hattı mutasyonları'\n",
            "' 2011'  ->'Youtube'\n",
            "' Fonksiyonel Gruplar'  ->'Fonksiyonel Gruplar'\n",
            "'%15'  ->'%15'\n",
            "' Davulcu'  ->'Davulcu'\n",
            "' reçine adı verilen madde'  ->'reçine '\n",
            "' dört'  ->'thrash metalin dört büyükleri'\n",
            "' biridir'  ->'Saburhane Camii'\n",
            "' Ossi Runne'  ->'18'\n",
            "' Câhiliyye'  ->'Câhiliyye Dönemiyle'\n",
            "' karaciğer'  ->'karaciğer'\n",
            "' iki takım'  ->'topla'\n",
            "' 25 milyondan fazla'  ->'25 milyondan fazla'\n",
            "''  ->'Londra Uluslararası Satranç Turnuvası'\n",
            "' Yunan'  ->'Yunan'\n",
            "' 30 gün çeker. Bir de erkek adıdır. Türkiye'de, Atatürk devrimine değin Sümer-Babil-İbrani-Süryani-Arami Tişri den gelme ad ile Teşrin-i Sani olan ayın adı Cumhuriyet'ten sonra İkinci Teşrin, İkinciteşrin olarak kullanıldı, 10 Ocak 1945'te kabul edilen 15 Ocak 1945'te yürürlüğe giren ve dört ayın adlarını değiştiren yasa ile ayın adı kasım yapıldı. 1946 yılında, Refet Ülgen eylül ayı için ilk güz, kasım ayı içinse songüz adını önermiş; ancak bu önerisi benimsenmemiştir. Ayın adı bir iddiaya göre Arapça kâsim, (bölen)'den gelmektedir, ama neyi bölmektedir? Oysa Anadolu'da, bu yasa çıkmadan yüzyıllar öncesinden beri halk yılı, kasım, kasım günleri ve hızır, hızır günleri  diye ikiye ayırır, hızır günleri 6 Mayıs günü ile başlar ve kasım'a dek sürer. Bir başka iddiaya göre ise, adın \"koç katımı\" ya da \"katım ayı\" olarak bilinen dönemin bu aya denk gelmesidir. 6 Mayıs günü Hızır ile İlyas (Ellez)'ın buluştuğuna inanılır. Kasım adının İngilizce karşılığı olan \"November\", Latince 9 anlamına gelen “novem” den gelir. Aylara bölünmemiş kış süreci, ocak ve şubat arasında bölünene kadar eski Roma takviminde kasım ayı 9.'  ->'11.'\n",
            "''  ->'art deco üslubunda'\n",
            "' Laufeyson, İskandinav mitolojisinde kötülük ve kurnazlık'  ->'kötülük ve kurnazlık'\n",
            "' Fransız litograf, matbaacı, sanat simsarı'  ->'litograf, matbaacı, sanat simsarı'\n",
            "'dan çıkan, “Nemo'  ->'2004'\n",
            "' Benito Mussolini'nin kurucusu olduğu Ulusal Faşist Parti'nin İtalya'da iktidara gelmesinin ardından'  ->'Ulusal Faşist Parti'nin İtalya'da iktidara gelmesinin ardından'\n",
            "'\"karaciğer'  ->'karaciğer'\n",
            "''  ->'Türk kadınının boşanma talebinde bulunabildiğini'\n",
            "' salgı bezidir'  ->'salgı bezi'\n",
            "' tüm vücudunu ya da gözünü'  ->'Güneş'\n",
            "'\"HIV pozitif\" veya \"HIV enfeksiyonlu\" denir'  ->'\"HIV pozitif\" veya \"HIV enfeksiyonlu\"'\n",
            "' bir bilgisayarın veya bilgisayar kontrolündeki bir robotun'  ->'bir bilgisayarın veya bilgisayar kontrolündeki bir robotun'\n",
            "' bir radyo istasyonu ve öğrenci kulübü'  ->'adyo istasyonu ve öğrenci kulübü'\n",
            "' 27'  ->'27'\n",
            "' 1904'  ->'1888'\n",
            "' ifade, tarihsel, sembolik anlamlarını minimuma indirmek'  ->'nesnenin nesne olma özelliğine dikkat çekmek ve ifade, tarihsel, sembolik anlamlarını minimuma indirmek'\n",
            "' bağımsız devlet Vatikanının'  ->'Vatikan'\n",
            "' 128 milyonun üzerindeki'  ->'Japonya'da insanlar ve Japon göçmen toplulukları tarafından'\n",
            "''  ->'Demeter ve Zeus'\n",
            "' yanlışlanmaya'  ->'yanlışlanmaya'\n",
            "'bir tutam endüstriyel etkileşimli agresif metal'  ->'bir tutam endüstriyel etkileşimli agresif metal'\n",
            "' 100 milyondan fazla'  ->'30'dan fazla'\n",
            "''  ->'kömür katranı '\n",
            "' Dünya Savaşı'  ->'II. Dünya Savaşı sırasında'\n",
            "' kurgu veya gerçek algı'  ->'kurgu veya gerçek algı'\n",
            "' Microsoft'  ->'Sun Microsystems'\n",
            "'Düşük gözlemlenebilir teknoloji'  ->'bir dizi askerî teknoloji yöntemi'\n",
            "' Thomas More'  ->'Thomas More'\n",
            "' MÖ 2500 yılında'  ->'MÖ 2500 yılında'\n",
            "'Adolphe'  ->'Jean-Léon Gérôme'\n",
            "' 14 yaşında ilk albümü yayımlanmıştı. 1985 yılında Rounder Records ile sözleşme imzalandı ve 1987'  ->'14'\n",
            "' Amerikalı gerçekçi yazar'  ->'Amerikalı gerçekçi yazardır'\n",
            "' Ti Jian Zi'  ->'Tüytop'\n",
            "''  ->'Baba (Peder), Oğul ve Kutsal Ruh (Rûhu'l-Kudüs)'\n",
            "' teoloji, bilim, tıp ve hukuk alan alanlarındaki birçok terimin kökeni Latinceye (ve Grekçeye)'  ->'teoloji, bilim, tıp ve hukuk'\n",
            "' pâtissier'  ->'hamur işi, tatlılar, ekmekler ve diğer unlu mamullerin yapımında usta, profesyonel bir mutfakta istasyon şefi ve aşçı'\n",
            "' Şehzade'  ->'Özbek bir şarkıcı'\n",
            "' 170'  ->'170'\n",
            "' 2001 Ağustos ayında'  ->'2001 Ağustos'\n",
            "' Polonyalı sosyalist politikacı, gazeteci ve Başbakanıydı'  ->'sosyalist politikacı, gazeteci ve Başbakan'\n",
            "' Orta Çağ ve Reformasyon'  ->'Orta Çağ ve Reformasyon'\n",
            "''  ->'çevrimiçi kamu erişim kataloğu'\n",
            "' üç'  ->'üç'\n",
            "' Güneydoğu Asya ve Uzak Doğu'  ->'Güneydoğu Asya ve Uzak Doğu'\n",
            "' Doğu Sibirya, Alaska, Kanada ve Grönland'  ->'Doğu Sibirya, Alaska, Kanada ve Grönland'\n",
            "' Cevat Karahasan'  ->'Cevat Karahasan'\n",
            "' théorie'  ->'Cehennemlik'\n",
            "' Tayvan, Singapur, Malezya, Endonezya'  ->'başta Çin olmak üzere Tayvan, Singapur, Malezya, Endonezya'\n",
            "' Polonyalı'  ->'siyasetçi ve diplomat'\n",
            "' Meksikalı'ya'  ->'Meksikalı'\n",
            "''  ->'Manchester'\n",
            "' 1754'  ->'1754'\n",
            "'İslam Tarihi'  ->'İslam Tarihi'\n",
            "' küçük sınıf otomobil'  ->'küçük sınıf otomobildir'\n",
            "' Latince 9'  ->'November'\n",
            "' 2,75'  ->'2,75'\n",
            "'Highest Hopes'  ->'Highest Hopes'\n",
            "'Düşük gözlemlenebilir teknoloji'  ->'tespit yöntemlerine göre daha az görünür yapmak için'\n",
            "' Cumhurbaşkanlığı kararnamesi'  ->'Cumhurbaşkanlığı kararnamesi'\n",
            "' Chuck Palahniuk'  ->'Chuck Palahniuk'\n",
            "' Mağribilerin'  ->'Mağribiler'\n",
            "' elektronik, kaynak, katot ışını tüpleri, elektron mikroskopları, radyoterapi, lazerler, gaz iyonlaştırma sayaçları ve parçacık hızlandırıcıları'  ->'elektronik, kaynak, katot ışını tüpleri, elektron mikroskopları, radyoterapi, lazerler, gaz iyonlaştırma sayaçları ve parçacık hızlandırıcıları'\n",
            "' ömür boyu'  ->'üç yaşından önce'\n",
            "' üçüncü ventrikülün'  ->'üçüncü ventrikülün'\n",
            "' Vlad Dracul'  ->'Vlad Dracul'\n",
            "' Trident denen üç dişli bir yabadır'  ->'Trident'\n",
            "''  ->'15 Ocak 1945'\n",
            "' Finlandiya cep telefonu üreticisi'  ->'cep telefonu'\n",
            "' Ortadoğu Tarihi yoğunluklu olmak üzere Tarih konusunda, doktorasınıysa İslam Tarihi'  ->'Ortadoğu Tarihi yoğunluklu olmak üzere Tarih'\n",
            "'Oral rehidrasyon tedavisi\" (ağızdan sıvı tedavisi)'  ->'\"Oral rehidrasyon tedavisi\" (ağızdan sıvı tedavisi)'\n",
            "' çağdaş şairi'  ->'dönemin popüler çağdaş şairi'\n",
            "' akut ve şiddetli ishal'  ->'akut ve şiddetli ishal'\n",
            "' Buz Devleriyle'  ->'Buz Devleriyle'\n",
            "' 25 milyon dolarlık'  ->'25 milyon dolarlık'\n",
            "' drama'  ->'bir jüri üyesinin diğer on bir jüri üyesini şüphelinin suçsuz olduğu konusunda, makul şüphe temelinde, ikna etme çabaları'\n",
            "' Schindler's List'  ->'Schindler's List'\n",
            "' Frank Darabont'  ->'Frank Darabont'\n",
            "' tanrıların yeryüzüne indiklerinde büründükleri şekillerdir. Balarama, Sri, Varaha gibi isimler alan avatarlar, hikâyelere konu olmuştur. Avatar, Sanskritçede ava; aşağı ve tar: iniş'  ->'tanrıların yeryüzüne indiklerinde büründükleri şekillerdir'\n",
            "' Keltus, Herakles ve Keltin'in oğludur. Keltus'  ->'Keltus'\n",
            "' Milattan önce 356'da Pella'da'  ->'Pella'\n",
            "' Rusya imparatorluk muhafız okulunda'  ->'imparatorluk muhafız okulunda'\n",
            "' fiyatlar genel düzeyinin sürekli ve hissedilir artışını'  ->'fiyatlar genel düzeyinin sürekli ve hissedilir artışını'\n",
            "' psikolog'  ->'psikolog'\n",
            "' 1980'  ->'1980’lerden beri'\n",
            "''  ->'Göktürk Yazıtları'\n",
            "' ağının sahibidir'  ->'Paris'\n",
            "' Katar ve Suudi Arabistan'dan'  ->'Katar ve Suudi Arabistan'dan'\n",
            "accuracy:=0.33\n",
            "before accuracy:=0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LZTn_LuP_CfF",
        "outputId": "32811ed8-b8a4-4311-c692-161e37f90671"
      },
      "source": [
        "results[0][\"question\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Başlıca İslam mezhepleri nelerdir?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgNdtluN-Dg5"
      },
      "source": [
        "with open(save_path + \"test-results/\" + model_save_name.split(\"/\")[0] + \"_10epoch_result.txt\", \"w\") as f:\n",
        "  for result in results:\n",
        "    f.write('%s\\n' %result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxgo-YipwZ6f"
      },
      "source": [
        "### Save Weights to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8xpx5lV2iYh"
      },
      "source": [
        "model.save_weights(save_path + \"weights/\" + model_save_name.split(\"/\")[0] + \"_10epoch_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}